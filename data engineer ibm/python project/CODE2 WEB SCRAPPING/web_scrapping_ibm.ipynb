{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oWOEDsd69rir"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://web.archive.org/web/20230902185655/https://en.everybodywiki.com/100_Most_Highly-Ranked_Films'\n",
        "db_name = 'Movies.db'\n",
        "table_name = 'Top_50'\n",
        "csv_path = 'top_50_films.csv'\n",
        "df = pd.DataFrame(columns=[\"Average Rank\",\"Film\",\"Year\"])\n",
        "count = 0"
      ],
      "metadata": {
        "id": "RUCGBsvX91gJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "html_page = requests.get(url).text\n",
        "data = BeautifulSoup(html_page, 'html.parser')"
      ],
      "metadata": {
        "id": "PVZO6rxn-BNV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tables = data.find_all('tbody')\n",
        "rows = tables[0].find_all('tr')"
      ],
      "metadata": {
        "id": "cHPDDelk-RY1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in rows:\n",
        "    if count<50:\n",
        "        col = row.find_all('td')\n",
        "        if len(col)!=0:\n",
        "            data_dict = {\"Average Rank\": col[0].contents[0],\n",
        "                         \"Film\": col[1].contents[0],\n",
        "                         \"Year\": col[2].contents[0]}\n",
        "            df1 = pd.DataFrame(data_dict, index=[0])\n",
        "            df = pd.concat([df,df1], ignore_index=True)\n",
        "            count+=1\n",
        "    else:\n",
        "        break"
      ],
      "metadata": {
        "id": "dpT6yhw__cCg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRt_ZY62_oE2",
        "outputId": "18e67701-63fb-417a-8770-83ce58a2618e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Average Rank                                           Film  Year\n",
            "0             1                                  The Godfather  1972\n",
            "1             2                                   Citizen Kane  1941\n",
            "2             3                                     Casablanca  1942\n",
            "3             4                         The Godfather, Part II  1974\n",
            "4             5                            Singin' in the Rain  1952\n",
            "5             6                                         Psycho  1960\n",
            "6             7                                    Rear Window  1954\n",
            "7             8                                 Apocalypse Now  1979\n",
            "8             9                          2001: A Space Odyssey  1968\n",
            "9            10                                  Seven Samurai  1954\n",
            "10           11                                        Vertigo  1958\n",
            "11           12                                    Sunset Blvd  1950\n",
            "12           13                                   Modern Times  1936\n",
            "13           14                             Lawrence of Arabia  1962\n",
            "14           15                             North by Northwest  1959\n",
            "15           16                                      Star Wars  1977\n",
            "16           17                                       Parasite  2019\n",
            "17           18                               Schindler's List  1993\n",
            "18           19  Lord of the Rings: The Fellowship of the Ring  2001\n",
            "19           20                           Shawshank Redemption  1994\n",
            "20           21                          It's a Wonderful Life  1946\n",
            "21           22                                   Pulp Fiction  1994\n",
            "22           23                              Avengers: Endgame  2019\n",
            "23           24                                    City Lights  1931\n",
            "24           25                One Flew Over the Cuckoo's Nest  1975\n",
            "25           26                                     Goodfellas  1990\n",
            "26           27                        Raiders of the Lost Ark  1981\n",
            "27           28                                   12 Angry Men  1957\n",
            "28           29                       The Silence of the Lambs  1991\n",
            "29           30                                    Taxi Driver  1976\n",
            "30           31                            Saving Private Ryan  1998\n",
            "31           32                     E.T. the Extra Terrestrial  1982\n",
            "32           33                                          Alien  1979\n",
            "33           34              Spider-Man: Into the Spider-verse  2018\n",
            "34           35                                   Blade Runner  1982\n",
            "35           36                               Double Indemnity  1944\n",
            "36           37                                The Dark Knight  2008\n",
            "37           38                               The Wizard of Oz  1939\n",
            "38           39  Star Wars: Episode V- The Empire Strikes Back  1980\n",
            "39           40                                  The Searchers  1956\n",
            "40           41                             Mad Max: Fury Road  2015\n",
            "41           42                                      Inception  2010\n",
            "42           43          Lord of the Rings: Return of the King  2003\n",
            "43           44                                     The Matrix  1999\n",
            "44           45                                     Fight Club  1999\n",
            "45           46                             Back to the Future  1985\n",
            "46           47                          It Happened One Night  1934\n",
            "47           48                The Good, the Bad, and the Ugly  1966\n",
            "48           49              Lord of the Rings: The Two Towers  2002\n",
            "49           50                                  All About Eve  1950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(csv_path)"
      ],
      "metadata": {
        "id": "acTV3AGDAM6m"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect(db_name)\n",
        "df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "3rcN7uXNAaz1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "EXPLANATION OF CODE\n",
        "\n",
        "import requests\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL of the webpage to scrape\n",
        "url = 'https://web.archive.org/web/20230902185655/https://en.everybodywiki.com/100_Most_Highly-Ranked_Films'\n",
        "\n",
        "# Database name, table name, and CSV file path\n",
        "db_name = 'Movies.db'\n",
        "table_name = 'Top_50'\n",
        "csv_path = '/home/project/top_50_films.csv'\n",
        "\n",
        "# Initialize an empty DataFrame with column names\n",
        "df = pd.DataFrame(columns=[\"Average Rank\", \"Film\", \"Year\"])\n",
        "\n",
        "# Counter to keep track of the number of rows processed\n",
        "count = 0\n",
        "\n",
        "# Fetch the HTML content of the webpage\n",
        "html_page = requests.get(url).text\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "data = BeautifulSoup(html_page, 'html.parser')\n",
        "\n",
        "# Find the table containing the desired data\n",
        "table = data.find('table')\n",
        "\n",
        "# Extract all rows from the table, skipping the header row\n",
        "rows = table.find_all('tr')[1:]\n",
        "\n",
        "# Loop through each row in the table\n",
        "for row in rows:\n",
        "    # Check if we have processed 50 rows\n",
        "    if count < 50:\n",
        "        # Extract all cells (columns) from the current row\n",
        "        cols = row.find_all('td')\n",
        "        # Check if there are any cells in the row\n",
        "        if len(cols) != 0:\n",
        "            # Extract text from each cell and strip any leading/trailing whitespace or tags\n",
        "            rank = cols[0].get_text(strip=True)\n",
        "            film = cols[1].get_text(strip=True)\n",
        "            year = cols[2].get_text(strip=True)\n",
        "            # Append the extracted data as a new row to the DataFrame\n",
        "            df = df.append({\"Average Rank\": rank, \"Film\": film, \"Year\": year}, ignore_index=True)\n",
        "            # Increment the row counter\n",
        "            count += 1\n",
        "    else:\n",
        "        # If 50 rows have been processed, exit the loop\n",
        "        break\n",
        "\n",
        "# Print the DataFrame containing the extracted data\n",
        "print(df)\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect(db_name)\n",
        "\n",
        "# Save the DataFrame as a table in the SQLite database\n",
        "df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
        "\n",
        "# Close the database connection\n",
        "conn.close()\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "woeQ8AzxCYuS",
        "outputId": "a99b0cc5-f34c-4b05-f98b-6bf2d3b4223f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nEXPLANATION OF CODE\\n\\nimport requests\\nimport sqlite3\\nimport pandas as pd\\nfrom bs4 import BeautifulSoup\\n\\n# URL of the webpage to scrape\\nurl = \\'https://web.archive.org/web/20230902185655/https://en.everybodywiki.com/100_Most_Highly-Ranked_Films\\'\\n\\n# Database name, table name, and CSV file path\\ndb_name = \\'Movies.db\\'\\ntable_name = \\'Top_50\\'\\ncsv_path = \\'/home/project/top_50_films.csv\\'\\n\\n# Initialize an empty DataFrame with column names\\ndf = pd.DataFrame(columns=[\"Average Rank\", \"Film\", \"Year\"])\\n\\n# Counter to keep track of the number of rows processed\\ncount = 0\\n\\n# Fetch the HTML content of the webpage\\nhtml_page = requests.get(url).text\\n\\n# Parse the HTML content using BeautifulSoup\\ndata = BeautifulSoup(html_page, \\'html.parser\\')\\n\\n# Find the table containing the desired data\\ntable = data.find(\\'table\\')\\n\\n# Extract all rows from the table, skipping the header row\\nrows = table.find_all(\\'tr\\')[1:]\\n\\n# Loop through each row in the table\\nfor row in rows:\\n    # Check if we have processed 50 rows\\n    if count < 50:\\n        # Extract all cells (columns) from the current row\\n        cols = row.find_all(\\'td\\')\\n        # Check if there are any cells in the row\\n        if len(cols) != 0:\\n            # Extract text from each cell and strip any leading/trailing whitespace or tags\\n            rank = cols[0].get_text(strip=True)\\n            film = cols[1].get_text(strip=True)\\n            year = cols[2].get_text(strip=True)\\n            # Append the extracted data as a new row to the DataFrame\\n            df = df.append({\"Average Rank\": rank, \"Film\": film, \"Year\": year}, ignore_index=True)\\n            # Increment the row counter\\n            count += 1\\n    else:\\n        # If 50 rows have been processed, exit the loop\\n        break\\n\\n# Print the DataFrame containing the extracted data\\nprint(df)\\n\\n# Save the DataFrame as a CSV file\\ndf.to_csv(csv_path, index=False)\\n\\n# Connect to the SQLite database\\nconn = sqlite3.connect(db_name)\\n\\n# Save the DataFrame as a table in the SQLite database\\ndf.to_sql(table_name, conn, if_exists=\\'replace\\', index=False)\\n\\n# Close the database connection\\nconn.close()\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FRq9deg_DDYs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}